{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L9eHRmhwdIET"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "import imageio\n",
        "import dlib\n",
        "from IPython.display import Image\n",
        "from google.colab.patches import cv2_imshow"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZbitixyEfdZ0"
      },
      "outputs": [],
      "source": [
        "!wget http://dlib.net/files/shape_predictor_68_face_landmarks.dat.bz2\n",
        "!bzip2 -d shape_predictor_68_face_landmarks.dat.bz2"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Function: `get_landmarks(image)`**  \n",
        "#### **Purpose:**  \n",
        "Detects facial landmarks for a given image using dlib's **face detector** and **shape predictor**.  \n",
        "\n",
        "#### **Key Features:**  \n",
        "- Returns **tie points (landmarks)** for the image, which include:  \n",
        "  - **68 facial landmark points** (e.g., eyes, nose, mouth, jawline) deteted by **dlib's frontal face detector**.  \n",
        "  - **4 corner points** of the image (top-left, top-right, bottom-left, bottom-right) added **manually**.   \n"
      ],
      "metadata": {
        "id": "dG2PmbyKQTMN"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3j_kUUvJdIEY"
      },
      "outputs": [],
      "source": [
        "# Load the pre-trained dlib face detector and shape predictor\n",
        "detector = dlib.get_frontal_face_detector()\n",
        "predictor = dlib.shape_predictor(\"shape_predictor_68_face_landmarks.dat\")  # Model file from step 1\n",
        "\n",
        "def get_landmarks(image):\n",
        "    '''\n",
        "    Function to generate tie points for an image using frontal face detector of dlib library which detects\n",
        "    68 facial features\n",
        "    '''\n",
        "\n",
        "    # Detect faces in the image\n",
        "    faces = detector(image)\n",
        "\n",
        "    if len(faces) == 0:\n",
        "        return []  # Return an empty list if no face is detected\n",
        "\n",
        "    face = faces[0]  # Select the first detected face\n",
        "\n",
        "    # 68 lanmark points\n",
        "    shape = predictor(image, face)\n",
        "    landmarks= [(shape.part(i).x, shape.part(i).y) for i in range(68)]  # 68 points\n",
        "\n",
        "    # corner points\n",
        "    landmarks.append((0, 0))\n",
        "    landmarks.append((image.shape[1] - 1, 0))\n",
        "    landmarks.append((0, image.shape[0] - 1))\n",
        "    landmarks.append((image.shape[1] - 1, image.shape[0] - 1))\n",
        "\n",
        "    return landmarks\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Function: `delaunay_triangulation(img1, points1)`**  \n",
        "#### **Purpose:**  \n",
        "Performs **Delaunay triangulation** on a given set of landmark points and returns a list of triangle indices.  \n",
        "\n",
        "#### **Key Steps:**  \n",
        "1. **Initialize Subdiv2D** with the image dimensions for triangulation.  \n",
        "2. **Insert landmark points** into the subdivision.  \n",
        "3. **Retrieve triangles** as coordinate sets from `subdiv.getTriangleList()`.  \n",
        "4. **Map each landmark point to its index** using a dictionary.  \n",
        "5. **Filter valid triangles** (within image boundaries) and convert their vertices into indices.  \n",
        "6. **Return a list of triangle indices**, where each triangle is represented by three landmark indices.  \n",
        "\n"
      ],
      "metadata": {
        "id": "tW9zarPlRegZ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hCGro835dIEU"
      },
      "outputs": [],
      "source": [
        "def delaunay_triangulation(img1, points1):\n",
        "\n",
        "    # Create a new Subdiv2D object using the bounding rectangle\n",
        "    subdiv = cv2.Subdiv2D((0, 0, img1.shape[1], img1.shape[0]))\n",
        "\n",
        "    # subdiv.insert(points1)\n",
        "    for pt in points1:\n",
        "      subdiv.insert(pt)\n",
        "\n",
        "    triangle_list = subdiv.getTriangleList()  # Get all triangles\n",
        "    h, w = img1.shape[:2]  # Get image dimensions\n",
        "\n",
        "    # Create a dictionary that maps each landmark point to its index in the points list\n",
        "    point_index_dict = {tuple(point): index for index, point in enumerate(points1)}\n",
        "\n",
        "    triangle_indices = []\n",
        "\n",
        "    for t in triangle_list:\n",
        "        pt1, pt2, pt3 = (t[0], t[1]), (t[2], t[3]), (t[4], t[5])  # Extract triangle vertices\n",
        "\n",
        "        # Check if the points are inside the image boundaries\n",
        "        if (0 <= pt1[0] < w and 0 <= pt1[1] < h and\n",
        "            0 <= pt2[0] < w and 0 <= pt2[1] < h and\n",
        "            0 <= pt3[0] < w and 0 <= pt3[1] < h):\n",
        "\n",
        "            pt1, pt2, pt3 = (int(t[0]), int(t[1])), (int(t[2]), int(t[3])), (int(t[4]), int(t[5]))  # Convert to integer\n",
        "\n",
        "            point_indices = (\n",
        "                point_index_dict.get((t[0], t[1])),\n",
        "                point_index_dict.get((t[2], t[3])),\n",
        "                point_index_dict.get((t[4], t[5])),\n",
        "            )\n",
        "            if None not in point_indices:\n",
        "                triangle_indices.append(point_indices)\n",
        "\n",
        "    return triangle_indices\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Function: `compute_morphed_triangle(img1, img2, triangle1, triangle2, triangle, alpha, result)`**\n",
        "#### **Purpose:**  \n",
        "Blends corresponding triangles from two images using **affine transformations** and **alpha blending** to create a smooth morphing effect.\n",
        "\n",
        "#### **Key Steps:**  \n",
        "1. **Extract Triangles:** Crop triangle regions from both images using bounding rectangles.  \n",
        "2. **Create Masks:** Generate binary masks to isolate the triangles.  \n",
        "3. **Affine Transformation:** Warp both triangles to match the target morphed triangle.  \n",
        "4. **Blend Triangles:** Use **alpha blending** to combine them smoothly.  \n",
        "5. **Merge into Output:** Insert the morphed triangle into the final result.  \n",
        "\n",
        "#### **Output:**  \n",
        "A seamlessly blended triangular region, contributing to a **smooth face morph**.\n"
      ],
      "metadata": {
        "id": "aPhyta8CSMFQ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EG0iILaEdIEV"
      },
      "outputs": [],
      "source": [
        "def compute_morphed_triangle(img1, img2, triangle1, triangle2, morphed_triangle, alpha, result):\n",
        "    \"\"\"\n",
        "    triangle1: Contains the (x, y) coordinates of the vertices of triangle1 in img1\n",
        "    triangle2: Contains the (x, y) coordinates of the vertices of triangle2 in img2\n",
        "    morphed_triangle: Contains the (x, y) coordinates of the vertices of the morphed triangle in the morphed image\n",
        "    \"\"\"\n",
        "    # Calculate the bounding rectangle for triangle1 and crop the triangle\n",
        "    rect1 = cv2.boundingRect(triangle1)\n",
        "    x1, y1, w1, h1 = rect1\n",
        "    cropped_triangle1 = img1[y1 : y1 + h1, x1 : x1 + w1]\n",
        "\n",
        "    # Calculate the bounding rectangle for triangle2 and crop the triangle\n",
        "    rect2 = cv2.boundingRect(triangle2)\n",
        "    x2, y2, w2, h2 = rect2\n",
        "    cropped_triangle2 = img2[y2 : y2 + h2, x2 : x2 + w2]\n",
        "\n",
        "    # Calculate the bounding rectangle for the morphed triangle and create a mask for it\n",
        "    r = cv2.boundingRect(morphed_triangle)\n",
        "    x, y, w, h = r\n",
        "\n",
        "    # Offset the points in the triangle so they are relative to the bounding rectangle\n",
        "    t1_offset = np.array(triangle1 - [x1, y1], np.int32)\n",
        "    t2_offset = np.array(triangle2 - [x2, y2], np.int32)\n",
        "    t_offset = np.array(morphed_triangle - [x, y], np.int32)\n",
        "\n",
        "    # Create a mask for the cropped triangle(single-channel, binary)\n",
        "    mask1 = np.zeros((h1, w1), np.uint8)\n",
        "    mask2 = np.zeros((h2, w2), np.uint8)\n",
        "    mask = np.zeros((h, w), np.uint8)\n",
        "\n",
        "    cv2.fillConvexPoly(mask1, t1_offset, (1.0, 1.0, 1.0), 16, 0)\n",
        "    cv2.fillConvexPoly(mask2, t2_offset, (1.0, 1.0, 1.0), 16, 0)\n",
        "    cv2.fillConvexPoly(mask, t_offset, (1.0, 1.0, 1.0), 16, 0)\n",
        "\n",
        "    # Apply the mask to the cropped triangle1\n",
        "    cropped_triangle1 = cv2.bitwise_and(cropped_triangle1, cropped_triangle1, mask=mask1)\n",
        "\n",
        "    # Apply the mask to the cropped triangle2\n",
        "    cropped_triangle2 = cv2.bitwise_and(cropped_triangle2, cropped_triangle2, mask=mask2)\n",
        "\n",
        "    # Transform triangle1 and triangle2 to the morphed triangle\n",
        "    t1_offset = np.float32(t1_offset)\n",
        "    t2_offset = np.float32(t2_offset)\n",
        "    t_offset = np.float32(t_offset)\n",
        "\n",
        "    # Calculate the affine transformation matrices for the first and second triangles\n",
        "    M1 = cv2.getAffineTransform(t1_offset, t_offset)\n",
        "    wrap_triangle1 = cv2.warpAffine(cropped_triangle1, M1, (w, h))\n",
        "\n",
        "    M2 = cv2.getAffineTransform(t2_offset, t_offset)\n",
        "    wrap_triangle2 = cv2.warpAffine(cropped_triangle2, M2, (w, h))\n",
        "\n",
        "    # Blend triangles\n",
        "    morphed_triangle = cv2.addWeighted(wrap_triangle1, 1 - alpha, wrap_triangle2, alpha, 0)\n",
        "\n",
        "    # Add the morphed triangle to the new image using the mask\n",
        "\n",
        "    for c in range(3):  # Loop over all three channels (RGB)\n",
        "        result[y:y+h, x:x+w, c] = ((1.0) - mask) * result[y:y+h, x:x+w, c] + morphed_triangle[:, :, c] * mask\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Function: `generate_morphed_points(points1, points2, alpha)`**  \n",
        "#### **Purpose:**  \n",
        "Computes **intermediate landmark positions** between two sets of points using **linear interpolation**.  \n",
        "\n",
        "#### **Key Steps:**  \n",
        "1. Iterate through each pair of corresponding points in `points1` and `points2`.  \n",
        "2. Compute **interpolated coordinates** using:  \n",
        "   $$ x = (1 - \\alpha) \\cdot x_1 + \\alpha \\cdot x_2 $$  \n",
        "   $$ y = (1 - \\alpha) \\cdot y_1 + \\alpha \\cdot y_2 $$  \n",
        "3. Return the list of **morphed points**.  \n",
        "\n",
        "#### **Output:**  \n",
        "A **list of tuples** representing the **interpolated landmark positions** for the given `alpha` value.  "
      ],
      "metadata": {
        "id": "8YI2TV8kLvA2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_morphed_points(points1, points2, alpha):\n",
        "    \"\"\"\n",
        "    Computes intermediate landmark positions using linear interpolation.\n",
        "    \"\"\"\n",
        "    morphed_points = [((1 - alpha) * p1[0] + alpha * p2[0],\n",
        "                      (1 - alpha) * p1[1] + alpha * p2[1])\n",
        "                      for p1, p2 in zip(points1, points2)]\n",
        "\n",
        "    return morphed_points"
      ],
      "metadata": {
        "id": "ZhdNcfUGJIXK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Function: `generate_morphed_frame(img1, img2, points1, points2, morphed_points, triangle_indices, alpha)`**  \n",
        "#### **Purpose:**  \n",
        "Generates a **single morphed frame** by warping and blending **triangular regions** between two images.  \n",
        "\n",
        "#### **Key Steps:**  \n",
        "1. **Initialize an empty image** to store the morphed frame.  \n",
        "2. Iterate over each **Delaunay triangle** index in `triangle_indices`:  \n",
        "   - Extract **corresponding triangles** from `img1`, `img2`, and the **interpolated** frame.  \n",
        "   - **Warp and blend** the triangles into the morphed image using `compute_morphed_triangle()`.  \n",
        "3. Apply **median filtering** (`cv2.medianBlur()`) to **smooth the output**.  \n",
        "4. Return the **final morphed frame**.  \n",
        "\n",
        "#### **Output:**  \n",
        "A **NumPy array** representing the **morphed frame** with blended image features.  "
      ],
      "metadata": {
        "id": "HIHqwUf-L8ue"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_morphed_frame(img1, img2, points1, points2, morphed_points, triangle_indices, alpha):\n",
        "    \"\"\"\n",
        "    Generates a single morphed frame by applying warping transformations on triangular regions.\n",
        "    \"\"\"\n",
        "    blended_image = np.zeros_like(img1)\n",
        "\n",
        "    for t in triangle_indices:\n",
        "        # Define corresponding triangles in both input images and the interpolated result\n",
        "        tri_img1 = np.array([points1[t[0]], points1[t[1]], points1[t[2]]], dtype=np.int32)\n",
        "        tri_img2 = np.array([points2[t[0]], points2[t[1]], points2[t[2]]], dtype=np.int32)\n",
        "        tri_morphed = np.array([morphed_points[t[0]], morphed_points[t[1]], morphed_points[t[2]]], dtype=np.int32)\n",
        "\n",
        "        # Apply transformation and blend the triangle into the output frame\n",
        "        compute_morphed_triangle(img1, img2, tri_img1, tri_img2, tri_morphed, alpha, blended_image)\n",
        "\n",
        "    return cv2.medianBlur(blended_image, 5)"
      ],
      "metadata": {
        "id": "bXQB5YogHI1s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Function: `create_morph_gif(img1, img2, points1, points2, filename='output1.gif')`**  \n",
        "#### **Purpose:**  \n",
        "Generates a **morphing animation (GIF)** between two face images using **Delaunay triangulation** and **image warping**.  \n",
        "\n",
        "#### **Key Steps:**  \n",
        "1. **Compute Delaunay triangulation** using `delaunay_triangulation(img1, points1)`.  \n",
        "2. **Initialize frames list** to store morphed images.  \n",
        "3. **Iterate over 50 steps (Î± âˆˆ [0,1])** ,i.e. 50 frames, to gradually blend `img1` and `img2`:  \n",
        "   - Compute **intermediate landmark points** using `generate_morphed_points()`.  \n",
        "   - Generate a **morphed frame** using `generate_morphed_frame()`.\n",
        "   - Append the processed frame to the list.  \n",
        "4. **Save the frames as a GIF** using `imageio.mimsave()`.  \n",
        "\n",
        "#### **Output:**  \n",
        "A smooth **face morphing animation** between `img1` and `img2`, saved as `output1.gif`. ðŸŽ­âœ¨  \n"
      ],
      "metadata": {
        "id": "wGoK7mQ5Tt92"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LKOvWDKudIEW"
      },
      "outputs": [],
      "source": [
        "def create_morph_gif(img1, img2, points1, points2, filename='output1.gif'):\n",
        "    \"\"\"\n",
        "    Generates a smooth transition from img1 to img2 by applying Delaunay triangulation-based morphing.\n",
        "    The function creates an animated GIF that illustrates the transformation process.\n",
        "    \"\"\"\n",
        "    # Generate triangulation indices for landmark points\n",
        "    triangle_indices = delaunay_triangulation(img1,points1)\n",
        "\n",
        "    # List to store individual transition frames\n",
        "    morph_frames = []\n",
        "\n",
        "    # Generate intermediate frames with varying blend ratios\n",
        "    for alpha in np.linspace(0, 1, 50):\n",
        "\n",
        "        # Compute interpolated landmark positions uding weighted avg\n",
        "        morphed_points = generate_morphed_points(points1, points2, alpha)\n",
        "\n",
        "        # generate morphed frame\n",
        "        morph_frames.append(generate_morphed_frame(img1, img2, points1, points2, morphed_points, triangle_indices, alpha))\n",
        "\n",
        "    # Export the generated frames as an animated GIF\n",
        "    imageio.mimsave(filename, morph_frames, fps=50)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Loading  Image input"
      ],
      "metadata": {
        "id": "lRgxyMGKTdXa"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4rP2nTptdIEW"
      },
      "outputs": [],
      "source": [
        "# Load an image from file\n",
        "img1 = cv2.imread(\"image1.jpg\")\n",
        "img2 = cv2.imread(\"image2.jpg\")\n",
        "\n",
        "# Validate image loading\n",
        "if img1 is None or img2 is None:\n",
        "    raise FileNotFoundError(\"One or both images could not be loaded. Please check the file paths.\")\n",
        "\n",
        "img1 = cv2.cvtColor(img1, cv2.COLOR_BGR2RGB)\n",
        "img2 = cv2.cvtColor(img2, cv2.COLOR_BGR2RGB)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Aq2HakfNdIEX"
      },
      "source": [
        "Part A - TIe pts giveen"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Reading tie points from text file and storing in lists"
      ],
      "metadata": {
        "id": "gvsab0SFT__8"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8DPWQnh4dIEY"
      },
      "outputs": [],
      "source": [
        "points1 = []\n",
        "points2 = []\n",
        "\n",
        "with open(\"points.txt\") as f:\n",
        "    num_of_tie_points = int(f.readline())\n",
        "    for _ in range(num_of_tie_points):\n",
        "        # Read each line of tie point coordinates and add them to their respective lists\n",
        "        x1, y1, x2, y2 = [int(i) for i in f.readline().split()]\n",
        "\n",
        "        points1.append((x1, y1))\n",
        "        points2.append((x2, y2))\n",
        "\n",
        "# Add the corner points to the list of points for the first image\n",
        "points1.append((0, 0))\n",
        "points1.append((img1.shape[1] - 1, 0))\n",
        "points1.append((0, img1.shape[0] - 1))\n",
        "points1.append((img1.shape[1] - 1, img1.shape[0] - 1))\n",
        "\n",
        "# Add the corner points to the list of points for the second image\n",
        "points2.append((0, 0))\n",
        "points2.append((img2.shape[1] - 1, 0))\n",
        "points2.append((0, img2.shape[0] - 1))\n",
        "points2.append((img2.shape[1] - 1, img2.shape[0] - 1))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v5gT2Z0SdIEY"
      },
      "outputs": [],
      "source": [
        "create_morph_gif(img1, img2, points1, points2, \"output1.gif\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Display the GIF\n",
        "Image(filename='output1.gif')"
      ],
      "metadata": {
        "id": "qY41JbKUSc9o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8hZS64OZdIEY"
      },
      "source": [
        "Part B- Ties pts not given"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Get landmarks for both images\n",
        "landmarks1 = get_landmarks(img1)\n",
        "landmarks2 = get_landmarks(img2)\n",
        "\n",
        "if not landmarks1 or not landmarks2:\n",
        "    raise ValueError(\"Landmarks could not be detected in one or both images. Please check the images.\")\n",
        "\n",
        "# Convert landmarks to arrays\n",
        "points1 = np.array(landmarks1)\n",
        "points2 = np.array(landmarks2)\n",
        "\n",
        "points1_list = [(int(pt[0]), int(pt[1])) for pt in points1]\n",
        "points2_list = [(int(pt[0]), int(pt[1])) for pt in points2]\n",
        "\n",
        "# Print the corresponding tie points\n",
        "print(\"Points from image 1:\", points1_list)\n",
        "print(\"Points from image 2:\", points2_list)"
      ],
      "metadata": {
        "id": "0BFjQLsdS7_w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "De_hg74PfIVT"
      },
      "outputs": [],
      "source": [
        "create_morph_gif(img1, img2, points1_list, points2_list, \"output2.gif\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YHhej-Lj580S"
      },
      "outputs": [],
      "source": [
        "# Display the GIF\n",
        "Image(filename='output2.gif')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Image morphing from human to animal by manually adding tie points**"
      ],
      "metadata": {
        "id": "yJbFou0uYJxH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Loading human and tiger picture"
      ],
      "metadata": {
        "id": "oYclyILVqZvS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load an image from file\n",
        "img1 = cv2.imread(\"human.jpg\")\n",
        "img2 = cv2.imread(\"tiger1.jpg\")\n",
        "\n",
        "# Validate image loading\n",
        "if img1 is None or img2 is None:\n",
        "    raise FileNotFoundError(\"One or both images could not be loaded. Please check the file paths.\")\n",
        "\n",
        "img1 = cv2.cvtColor(img1, cv2.COLOR_BGR2RGB)\n",
        "img2 = cv2.cvtColor(img2, cv2.COLOR_BGR2RGB)"
      ],
      "metadata": {
        "id": "io5eyaRgYWQK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Performing morphing on human and tiger image by manually marking tie points"
      ],
      "metadata": {
        "id": "YCcwQaSoQIOL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "points1 = []\n",
        "points2 = []\n",
        "\n",
        "with open(\"points2.txt\") as f:\n",
        "    num_of_tie_points = int(f.readline())\n",
        "    for _ in range(num_of_tie_points):\n",
        "        # Read each line of tie point coordinates and add them to their respective lists\n",
        "        x1, y1, x2, y2 = [int(i) for i in f.readline().split()]\n",
        "\n",
        "        points1.append((x1, y1))\n",
        "        points2.append((x2, y2))\n",
        "\n",
        "# Add the corner points to the list of points for the first image\n",
        "points1.append((0, 0))\n",
        "points1.append((img1.shape[1] - 1, 0))\n",
        "points1.append((0, img1.shape[0] - 1))\n",
        "points1.append((img1.shape[1] - 1, img1.shape[0] - 1))\n",
        "\n",
        "# Add the corner points to the list of points for the second image\n",
        "points2.append((0, 0))\n",
        "points2.append((img2.shape[1] - 1, 0))\n",
        "points2.append((0, img2.shape[0] - 1))\n",
        "points2.append((img2.shape[1] - 1, img2.shape[0] - 1))"
      ],
      "metadata": {
        "id": "KCPrIFxYoRF5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Performing image morphing showing transition from human to tiger"
      ],
      "metadata": {
        "id": "601g5aPFqd6q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "create_morph_gif(img1, img2, points1, points2, \"output.gif\")"
      ],
      "metadata": {
        "id": "yipSSVS8oV5q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Display the GIF\n",
        "Image(filename='output.gif')"
      ],
      "metadata": {
        "id": "-bS79kpoodxl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Methodology Used**  \n",
        "\n",
        "1. **Delaunay Triangulation:**  \n",
        "   - Generate **triangular meshes** over the face using **Delaunay triangulation**, ensuring consistent triangular regions for both images.  \n",
        "\n",
        "2. **Landmark Point Interpolation:**  \n",
        "   - Compute **intermediate feature points** by **linearly interpolating** between corresponding points in `img1` and `img2` for different blending ratios (Î± âˆˆ [0,1]).  \n",
        "\n",
        "3. **Triangle Warping & Blending:**  \n",
        "   - For each triangle, apply **affine transformation** to warp corresponding regions from both images.  \n",
        "   - Blend the transformed regions proportionally based on Î±.  \n",
        "\n",
        "4. **Frame Generation:**  \n",
        "   - Repeat the process over 50 steps, storing intermediate **morphed frames**.  \n",
        "   - Apply **median filtering** to smooth transitions.  \n",
        "\n",
        "5. **GIF Creation:**  \n",
        "   - Combine all frames into a **GIF animation** using `imageio.mimsave()`.  "
      ],
      "metadata": {
        "id": "3n5kCzIuic6h"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "For tie points generation, I have used frontal face detector of dlib library which detects  68 facial points. Additionally, I have added the corner points."
      ],
      "metadata": {
        "id": "16AzlRyhinju"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "vM5tnjmIVs7F"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}